{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a spam filtering system on based of bloom filtering.\n",
    "\n",
    "First we need to install the database from :- https://www.kaggle.com/datasets/ozlerhakan/spam-or-not-spam-dataset\n",
    "\n",
    "And another dataset from :- https://archive.ics.uci.edu/dataset/94/spambase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_9776\\2062208196.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam_or_not_spam.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained English language model with medium-sized word vectors\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_vector(email):\n",
    "    # Process the email with spaCy\n",
    "    doc = nlp(email)\n",
    "\n",
    "    # Extract word vectors and calculate the average vector\n",
    "    word_vectors = [token.vector for token in doc if token.has_vector]\n",
    "    \n",
    "    if word_vectors:\n",
    "        avg_vector = np.mean(word_vectors, axis=0)\n",
    "        return avg_vector\n",
    "    else:\n",
    "        # If no word vectors are found, return a zero vector\n",
    "        return np.zeros(nlp.vocab.vectors.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emails(df):\n",
    "    vectors = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        email = row['email']\n",
    "        label = row['label']\n",
    "        email = str(email)\n",
    "        # Convert email to vector\n",
    "        vector = email_to_vector(email)\n",
    "\n",
    "        # Append vector and label to lists\n",
    "        vectors.append(vector)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(vectors), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors:\n",
      " [[-0.34246749 -0.31992501 -1.38089931 ... -1.76729345 -1.80014443\n",
      "   0.03079836]\n",
      " [-1.0956682   1.04971981 -2.71677542 ... -1.53641939 -3.20208693\n",
      "   1.19321811]\n",
      " [-1.69103181  0.94615138 -1.79006374 ... -1.25015318 -2.36384511\n",
      "   1.25686538]\n",
      " [-0.8480776   0.58890224 -1.95315635 ... -1.97730875 -1.83998895\n",
      "   0.63771141]\n",
      " [-0.87737048  1.10694838 -2.03774714 ... -1.11400509 -3.75652146\n",
      "   1.08556521]]\n",
      "Labels:\n",
      " [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Process emails and labels\n",
    "vectors, labels = process_emails(df)\n",
    "\n",
    "# Print vectors and labels\n",
    "print(\"Vectors:\\n\", vectors[:5])\n",
    "print(\"Labels:\\n\", labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloom Filter Accuracy: 0.8966666666666666\n"
     ]
    }
   ],
   "source": [
    "from pybloom_live import ScalableBloomFilter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Bloom filter on the training set\n",
    "bloom_filter = ScalableBloomFilter(mode=ScalableBloomFilter.SMALL_SET_GROWTH)\n",
    "for vector, label in zip(X_train, y_train):\n",
    "    if label == 1:  # Spam\n",
    "        bloom_filter.add(vector.tobytes())\n",
    "\n",
    "# Test the Bloom filter on the testing set\n",
    "predictions = [1 if bloom_filter.__contains__(vector.tobytes()) else 0 for vector in X_test]\n",
    "\n",
    "# Evaluate the accuracy of the Bloom filter\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Bloom Filter Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive rate (TPR):  1.0\n",
      "False Positive Rate (FPR): 0.12277227722772277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Convert confusion matrix to a Pandas DataFrame\n",
    "confusion_matrix_df = pd.DataFrame(cm, index=['Actual Positive', 'Actual Negative'], columns=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "TP = confusion_matrix_df.loc['Actual Positive', 'Predicted Positive']\n",
    "TN = confusion_matrix_df.loc['Actual Negative', 'Predicted Negative']\n",
    "FP = confusion_matrix_df.loc['Actual Negative', 'Predicted Positive']\n",
    "FN = confusion_matrix_df.loc['Actual Positive', 'Predicted Negative']\n",
    "\n",
    "# Calculate true positive rate (sensitivity)\n",
    "tpr = TP / (TP + FN)\n",
    "fpr = FP / (TP + FN)\n",
    "\n",
    "print(\"True Positive rate (TPR): \", tpr)\n",
    "print(\"False Positive Rate (FPR):\", fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
