{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamKM++:\n",
      "Purity: 0.20875\n",
      "SSE: 199905.34241787193\n",
      "Silhouette Score: 0.7590772654456193\n",
      "\n",
      "CluStream:\n",
      "Purity: 0.2049\n",
      "SSE: 2312435.5539868665\n",
      "Silhouette Score: 0.5541789858672842\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "class StreamKMeansPP:\n",
    "    def __init__(self, n_clusters=8, max_iter=100, tol=1e-4, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.random_state = random_state\n",
    "        self.cluster_centers_ = None\n",
    "        self.labels_ = None\n",
    "        self.inertia_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "\n",
    "        # Choose the first centroid uniformly at random from the dataset\n",
    "        centroid_indices = [rng.integers(low=0, high=X.shape[0])]\n",
    "        centroids = X[centroid_indices]\n",
    "\n",
    "        # Choose the remaining centroids\n",
    "        for _ in range(1, self.n_clusters):\n",
    "            distances = np.array([min(np.linalg.norm(x - c)**2 for c in centroids) for x in X])\n",
    "            probs = distances / np.sum(distances)\n",
    "            centroid_indices.append(rng.choice(len(X), p=probs))\n",
    "            centroids = X[centroid_indices]\n",
    "\n",
    "        self.cluster_centers_ = centroids\n",
    "\n",
    "        # Assign points to clusters\n",
    "        self.labels_ = np.array([np.argmin([np.linalg.norm(x - c)**2 for c in centroids]) for x in X])\n",
    "\n",
    "        # Update centroids iteratively\n",
    "        for _ in range(self.max_iter):\n",
    "            new_centroids = np.array([np.mean(X[self.labels_ == i], axis=0) for i in range(self.n_clusters)])\n",
    "\n",
    "            # Check convergence\n",
    "            if np.sum(np.linalg.norm(new_centroids - centroids, axis=1)) < self.tol:\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "            self.cluster_centers_ = centroids\n",
    "            self.labels_ = np.array([np.argmin([np.linalg.norm(x - c)**2 for c in centroids]) for x in X])\n",
    "\n",
    "        # Calculate inertia\n",
    "        self.inertia_ = sum(min(np.linalg.norm(x - c)**2 for c in centroids) for x in X)\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        self.fit(X)\n",
    "        return self.labels_\n",
    "\n",
    "class SimpleCluStream:\n",
    "    def __init__(self, k, beta, decay_factor):\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.decay_factor = decay_factor\n",
    "        self.centroids = np.zeros((k, num_attributes))\n",
    "        self.counts = np.zeros(k)\n",
    "        self.weights = np.zeros(k)\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        for x in X:\n",
    "            min_dist = np.inf\n",
    "            min_idx = -1\n",
    "            for i, centroid in enumerate(self.centroids):\n",
    "                dist = np.linalg.norm(x - centroid)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_idx = i\n",
    "            self.centroids[min_idx] += self.decay_factor * (x - self.centroids[min_idx])\n",
    "            self.counts[min_idx] += 1\n",
    "            self.weights[min_idx] += self.decay_factor\n",
    "\n",
    "            if np.sum(self.weights) > self.beta:\n",
    "                nonzero_weights = self.weights[self.weights != 0]\n",
    "                if len(nonzero_weights) > 0:\n",
    "                    self.centroids[self.weights != 0] /= nonzero_weights[:, None]\n",
    "                    self.weights = np.zeros(self.k)\n",
    "\n",
    "    def predict(self, X):\n",
    "        labels = []\n",
    "        for x in X:\n",
    "            min_dist = np.inf\n",
    "            min_idx = -1\n",
    "            for i, centroid in enumerate(self.centroids):\n",
    "                dist = np.linalg.norm(x - centroid)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_idx = i\n",
    "            labels.append(min_idx)\n",
    "        return np.array(labels)\n",
    "\n",
    "\n",
    "# Generating synthetic data stream\n",
    "def generate_synthetic_data(num_attributes, num_data):\n",
    "    X, _ = make_blobs(n_samples=num_data, n_features=num_attributes, centers=5, random_state=42)\n",
    "    return X\n",
    "\n",
    "\n",
    "# Purity calculation\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = np.zeros((len(np.unique(y_true)), len(np.unique(y_pred))))\n",
    "    for i in range(len(y_true)):\n",
    "        contingency_matrix[y_true[i], y_pred[i]] += 1\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "\n",
    "# Sum of Squared Error (SSE) calculation\n",
    "def calculate_sse(X, centroids, labels):\n",
    "    sse = 0\n",
    "    for i in range(len(X)):\n",
    "        centroid = centroids[labels[i]]\n",
    "        sse += np.sum((X[i] - centroid) ** 2)\n",
    "    return sse\n",
    "\n",
    "\n",
    "# Applying StreamKM++ and simple CluStream and evaluating\n",
    "def evaluate_clustering(X, k):\n",
    "    # Applying StreamKM++\n",
    "    streamkm_pp = StreamKMeansPP(n_clusters=k, random_state=42)\n",
    "    streamkm_pp.fit(X)\n",
    "    streamkm_pp_labels = streamkm_pp.labels_\n",
    "\n",
    "    # Simple CluStream\n",
    "    simple_clustream = SimpleCluStream(k=k, beta=100, decay_factor=0.01)\n",
    "    for i in range(len(X)):\n",
    "        simple_clustream.partial_fit([X[i]])\n",
    "    clustream_labels = simple_clustream.predict(X)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    purity_streamkm_pp = purity_score(labels_true, streamkm_pp_labels)\n",
    "    sse_streamkm_pp = calculate_sse(X, streamkm_pp.cluster_centers_, streamkm_pp_labels)\n",
    "    silhouette_streamkm_pp = silhouette_score(X, streamkm_pp_labels)\n",
    "\n",
    "    purity_clustream = purity_score(labels_true, clustream_labels)\n",
    "    sse_clustream = calculate_sse(X, simple_clustream.centroids, clustream_labels)\n",
    "    silhouette_clustream = silhouette_score(X, clustream_labels)\n",
    "\n",
    "    # Print results\n",
    "    print(\"StreamKM++:\")\n",
    "    print(\"Purity:\", purity_streamkm_pp)\n",
    "    print(\"SSE:\", sse_streamkm_pp)\n",
    "    print(\"Silhouette Score:\", silhouette_streamkm_pp)\n",
    "\n",
    "    print(\"\\nCluStream:\")\n",
    "    print(\"Purity:\", purity_clustream)\n",
    "    print(\"SSE:\", sse_clustream)\n",
    "    print(\"Silhouette Score:\", silhouette_clustream)\n",
    "\n",
    "\n",
    "# Generating synthetic data stream\n",
    "num_attributes = 10\n",
    "num_data = 20000\n",
    "X = generate_synthetic_data(num_attributes, num_data)\n",
    "\n",
    "# Generate some random labels for evaluation\n",
    "labels_true = np.random.randint(0, 5, size=num_data)\n",
    "\n",
    "# Applying StreamKM++ and simple CluStream and evaluating\n",
    "k = 5  # Number of clusters\n",
    "evaluate_clustering(X, k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
